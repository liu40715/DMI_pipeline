[2025-07-28T12:40:42.801+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-28T12:40:43.027+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-28T12:40:43.039+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-28T12:40:43.040+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-28T12:40:43.055+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-28T12:40:43.069+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmphi8_ji83']
[2025-07-28T12:40:43.073+0000] {standard_task_runner.py:91} INFO - Job 44: Subtask transform_data_task
[2025-07-28T12:40:43.073+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3413) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-28T12:40:43.074+0000] {standard_task_runner.py:63} INFO - Started process 3415 to run task
[2025-07-28T12:40:43.172+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 1171f9d2ced8
[2025-07-28T12:40:43.299+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-28T12:40:43.300+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-28T12:40:43.310+0000] {logging_mixin.py:188} INFO - Fetching data from Redis key: ***_data:dag_bbbbbbb
[2025-07-28T12:40:43.331+0000] {logging_mixin.py:188} INFO - Applying algorithm 'aggregate_product_data' from module 'processor.transform.algos_1'
[2025-07-28T12:40:43.341+0000] {logging_mixin.py:188} INFO - Transformed data stored back to Redis with key: ***_data:dag_bbbbbbb
[2025-07-28T12:40:43.352+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-28T12:40:43.352+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-28T12:40:43.360+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250728T124043, end_date=20250728T124043
[2025-07-28T12:40:43.409+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-28T12:40:43.450+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-28T12:40:43.454+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-07-29T00:35:42.518+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-29T00:35:42.538+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T00:35:42.543+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T00:35:42.543+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-29T00:35:42.552+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-29T00:35:42.558+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=566) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-29T00:35:42.559+0000] {standard_task_runner.py:63} INFO - Started process 568 to run task
[2025-07-29T00:35:42.559+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmpn3hi77mz']
[2025-07-29T00:35:42.560+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask transform_data_task
[2025-07-29T00:35:42.702+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host ee0266895495
[2025-07-29T00:35:42.775+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-29T00:35:42.775+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-29T00:35:42.786+0000] {logging_mixin.py:188} INFO - Fetching data from Redis key: ***_data:dag_bbbbbbb
[2025-07-29T00:35:42.825+0000] {logging_mixin.py:188} INFO - Applying algorithm 'aggregate_product_data' from module 'processor.transform.algos_1'
[2025-07-29T00:35:42.837+0000] {logging_mixin.py:188} INFO - Transformed data stored back to Redis with key: ***_data:dag_bbbbbbb
[2025-07-29T00:35:42.848+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-29T00:35:42.849+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-29T00:35:42.858+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250729T003542, end_date=20250729T003542
[2025-07-29T00:35:42.893+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-29T00:35:43.019+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-29T00:35:43.024+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-07-29T06:01:54.352+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-29T06:01:54.376+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T06:01:54.383+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T06:01:54.383+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-29T06:01:54.393+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-29T06:01:54.400+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=9377) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-29T06:01:54.401+0000] {standard_task_runner.py:63} INFO - Started process 9379 to run task
[2025-07-29T06:01:54.401+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmp063xhaqu']
[2025-07-29T06:01:54.402+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask transform_data_task
[2025-07-29T06:01:54.543+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host ee0266895495
[2025-07-29T06:01:54.618+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-29T06:01:54.618+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-29T06:01:54.629+0000] {logging_mixin.py:188} INFO - 測試轉換層
[2025-07-29T06:01:54.629+0000] {logging_mixin.py:188} INFO - Fetching data from Redis key: ***_data:dag_bbbbbbb
[2025-07-29T06:01:54.630+0000] {logging_mixin.py:188} INFO - Applying algorithm 'aggregate_product_data' from module 'processor.transform.algos_1'
[2025-07-29T06:01:54.651+0000] {logging_mixin.py:188} INFO - Transformed data stored back to Redis with key: ***_data:dag_bbbbbbb
[2025-07-29T06:01:54.662+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-29T06:01:54.662+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-29T06:01:54.671+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250729T060154, end_date=20250729T060154
[2025-07-29T06:01:54.735+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-29T06:01:54.862+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-29T06:01:54.868+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-07-29T06:02:24.653+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-29T06:02:24.686+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T06:02:24.694+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-29T06:02:24.695+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-29T06:02:24.706+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-29T06:02:24.713+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=9431) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-29T06:02:24.713+0000] {standard_task_runner.py:63} INFO - Started process 9433 to run task
[2025-07-29T06:02:24.713+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmp41sc6so7']
[2025-07-29T06:02:24.714+0000] {standard_task_runner.py:91} INFO - Job 24: Subtask transform_data_task
[2025-07-29T06:02:24.875+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host ee0266895495
[2025-07-29T06:02:24.960+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-29T06:02:24.961+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-29T06:02:24.973+0000] {logging_mixin.py:188} INFO - 測試轉換層
[2025-07-29T06:02:24.974+0000] {logging_mixin.py:188} INFO - Fetching data from Redis key: ***_data:dag_bbbbbbb
[2025-07-29T06:02:24.976+0000] {logging_mixin.py:188} INFO - Applying algorithm 'aggregate_product_data' from module 'processor.transform.algos_1'
[2025-07-29T06:02:25.001+0000] {logging_mixin.py:188} INFO - Transformed data stored back to Redis with key: ***_data:dag_bbbbbbb
[2025-07-29T06:02:25.017+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-29T06:02:25.018+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-29T06:02:25.027+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250729T060224, end_date=20250729T060225
[2025-07-29T06:02:25.047+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-29T06:02:25.156+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-29T06:02:25.161+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-07-30T05:46:28.984+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-30T05:46:29.014+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-30T05:46:29.019+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-30T05:46:29.020+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-30T05:46:29.029+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-30T05:46:29.035+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=310) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-30T05:46:29.036+0000] {standard_task_runner.py:63} INFO - Started process 312 to run task
[2025-07-30T05:46:29.035+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmpd5ltfk7t']
[2025-07-30T05:46:29.037+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask transform_data_task
[2025-07-30T05:46:29.251+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 14614e29d246
[2025-07-30T05:46:29.315+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-30T05:46:29.316+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-30T05:46:29.325+0000] {logging_mixin.py:188} INFO - 測試轉換層
[2025-07-30T05:46:29.325+0000] {logging_mixin.py:188} INFO - transform_data_task
[2025-07-30T05:46:29.326+0000] {logging_mixin.py:188} INFO - ['_AssociationProxy_dag_run_128923708805664_inst', '__abstract__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__mapper__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__table__', '__table_args__', '__tablename__', '__weakref__', '_check_and_change_state_before_execution', '_clear_xcom_data', '_command_as_list', '_create_logger_name', '_execute_task', '_execute_task_with_callbacks', '_get_dagrun', '_get_log', '_handle_reschedule', '_log', '_log_config_logger_name', '_logger_name', '_register_dataset_changes', '_run_execute_callback', '_run_raw_task', '_sa_class_manager', '_sa_instance_state', '_sa_registry', '_schedule_downstream_tasks', '_set_context', '_set_state', '_task_display_property_value', '_try_number', 'are_dependencies_met', 'are_dependents_done', 'check_and_change_state_before_execution', 'clear_db_references', 'clear_next_method_args', 'clear_xcom_data', 'command_as_list', 'current_state', 'custom_operator_name', 'dag_id', 'dag_model', 'dag_run', 'defer_task', 'dry_run', 'duration', 'email_alert', 'emit_state_change_metric', 'end_date', 'error', 'execution_date', 'executor_config', 'external_executor_id', 'fetch_handle_failure_context', 'filter_for_tis', 'generate_command', 'get_dagrun', 'get_email_subject_content', 'get_failed_dep_statuses', 'get_num_running_task_instances', 'get_previous_dagrun', 'get_previous_execution_date', 'get_previous_start_date', 'get_previous_ti', 'get_relevant_upstream_map_indexes', 'get_rendered_k8s_spec', 'get_rendered_template_fields', 'get_task_instance', 'get_template_context', 'get_truncated_error_traceback', 'handle_failure', 'hostname', 'init_on_load', 'init_run_context', 'insert_mapping', 'is_eligible_to_retry', 'is_premature', 'is_trigger_log_context', 'job_id', 'key', 'log', 'log_url', 'logger', 'map_index', 'mark_success_url', 'max_tries', 'metadata', 'next_kwargs', 'next_method', 'next_retry_datetime', 'next_try_number', 'note', 'operator', 'operator_name', 'overwrite_params_with_dag_run_conf', 'pid', 'pool', 'pool_slots', 'prev_attempted_tries', 'previous_start_date_success', 'previous_ti', 'previous_ti_success', 'priority_weight', 'queue', 'queued_by_job', 'queued_by_job_id', 'queued_dttm', 'raw', 'ready_for_retry', 'refresh_from_db', 'refresh_from_task', 'registry', 'render_k8s_pod_yaml', 'render_templates', 'rendered_map_index', 'rendered_task_instance_fields', 'run', 'run_as_user', 'run_id', 'save_to_db', 'schedule_downstream_tasks', 'set_duration', 'set_state', 'start_date', 'state', 'stats_tags', 'task', 'task_display_name', 'task_id', 'task_instance_note', 'test_mode', 'ti_selector_condition', 'trigger', 'trigger_id', 'trigger_timeout', 'triggerer_job', 'try_number', 'unixname', 'updated_at', 'xcom_pull', 'xcom_push']
[2025-07-30T05:46:29.326+0000] {logging_mixin.py:188} INFO - 2222222222222222222222222222222
[2025-07-30T05:46:29.326+0000] {logging_mixin.py:188} INFO - Fetching data from Redis key: ***_data:dag_bbbbbbb
[2025-07-30T05:46:29.328+0000] {logging_mixin.py:188} INFO - Applying algorithm 'aggregate_product_data' from module 'processor.transform.algos_1'
[2025-07-30T05:46:29.361+0000] {logging_mixin.py:188} INFO - Transformed data stored back to Redis with key: ***_data:dag_bbbbbbb
[2025-07-30T05:46:29.373+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-30T05:46:29.374+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-30T05:46:29.380+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250730T054629, end_date=20250730T054629
[2025-07-30T05:46:29.409+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-30T05:46:29.564+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-30T05:46:29.570+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-07-31T02:12:55.577+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-31T02:12:55.694+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-31T02:12:55.699+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-07-31T02:12:55.699+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-07-31T02:12:55.710+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-07-31T02:12:55.716+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7792) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-31T02:12:55.717+0000] {standard_task_runner.py:63} INFO - Started process 7799 to run task
[2025-07-31T02:12:55.717+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '141', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator_python.py', '--cfg-path', '/tmp/tmpxhdor90v']
[2025-07-31T02:12:55.718+0000] {standard_task_runner.py:91} INFO - Job 141: Subtask transform_data_task
[2025-07-31T02:12:55.760+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 14614e29d246
[2025-07-31T02:12:55.833+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-07-31T02:12:55.834+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-31T02:12:55.848+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-07-31T02:12:55.848+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-07-31T02:12:55.848+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-07-31T02:12:55.854+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-07-31T02:12:55.856+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-07-31T02:12:55.909+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-07-31T02:12:55.910+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-07-31T02:12:55.911+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-07-31T02:12:55.926+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-31T02:12:55.927+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-31T02:12:55.935+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250731T021255, end_date=20250731T021255
[2025-07-31T02:12:55.970+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-31T02:12:55.996+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-31T02:12:55.998+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-01T05:19:09.251+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-01T05:19:09.438+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-01T05:19:09.464+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-01T05:19:09.464+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-01T05:19:09.480+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-01T05:19:09.488+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=14655) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-01T05:19:09.489+0000] {standard_task_runner.py:63} INFO - Started process 14657 to run task
[2025-08-01T05:19:09.489+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '198', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmp0uuo3lmt']
[2025-08-01T05:19:09.490+0000] {standard_task_runner.py:91} INFO - Job 198: Subtask transform_data_task
[2025-08-01T05:19:09.540+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 14614e29d246
[2025-08-01T05:19:09.651+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-01T05:19:09.652+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-01T05:19:09.664+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-01T05:19:09.664+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-01T05:19:09.664+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-01T05:19:09.671+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-01T05:19:09.674+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-01T05:19:09.707+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-01T05:19:09.707+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-01T05:19:09.709+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-01T05:19:09.709+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-01T05:19:09.724+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-01T05:19:09.725+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-01T05:19:09.734+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250801T051909, end_date=20250801T051909
[2025-08-01T05:19:09.783+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-01T05:19:09.815+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-01T05:19:09.819+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T06:45:04.470+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T06:45:04.499+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:45:04.505+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:45:04.505+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T06:45:04.517+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T06:45:04.529+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=421) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T06:45:04.530+0000] {standard_task_runner.py:63} INFO - Started process 423 to run task
[2025-08-03T06:45:04.529+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmp3qk1rcr6']
[2025-08-03T06:45:04.531+0000] {standard_task_runner.py:91} INFO - Job 5: Subtask transform_data_task
[2025-08-03T06:45:04.759+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 19828dfd2b76
[2025-08-03T06:45:04.830+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T06:45:04.831+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T06:45:04.845+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T06:45:04.845+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T06:45:04.846+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T06:45:04.855+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:45:04.858+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-03T06:45:04.930+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-03T06:45:04.931+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-03T06:45:04.935+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T06:45:04.936+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:45:04.966+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T06:45:04.967+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T06:45:04.987+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T064504, end_date=20250803T064504
[2025-08-03T06:45:05.024+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T06:45:05.241+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T06:45:05.245+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T06:45:34.770+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T06:45:34.793+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:45:34.798+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:45:34.798+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T06:45:34.808+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T06:45:34.814+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=478) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T06:45:34.815+0000] {standard_task_runner.py:63} INFO - Started process 487 to run task
[2025-08-03T06:45:34.814+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmpoiymu1uv']
[2025-08-03T06:45:34.816+0000] {standard_task_runner.py:91} INFO - Job 10: Subtask transform_data_task
[2025-08-03T06:45:35.037+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 19828dfd2b76
[2025-08-03T06:45:35.104+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T06:45:35.105+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T06:45:35.117+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T06:45:35.117+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T06:45:35.117+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T06:45:35.127+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:45:35.129+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-03T06:45:35.159+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-03T06:45:35.159+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-03T06:45:35.161+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T06:45:35.161+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:45:35.175+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T06:45:35.175+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T06:45:35.182+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T064534, end_date=20250803T064535
[2025-08-03T06:45:35.229+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T06:45:35.415+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T06:45:35.418+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T06:51:40.420+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T06:51:40.448+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:51:40.458+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:51:40.459+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T06:51:40.472+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T06:51:40.482+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=924) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T06:51:40.483+0000] {standard_task_runner.py:63} INFO - Started process 926 to run task
[2025-08-03T06:51:40.483+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmpe9dpi1w9']
[2025-08-03T06:51:40.486+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask transform_data_task
[2025-08-03T06:51:40.796+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 19828dfd2b76
[2025-08-03T06:51:40.939+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T06:51:40.940+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T06:51:40.954+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T06:51:40.955+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T06:51:40.955+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T06:51:40.965+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:51:40.969+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-03T06:51:41.001+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-03T06:51:41.001+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-03T06:51:41.003+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T06:51:41.004+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:51:41.018+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T06:51:41.019+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T06:51:41.031+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T065140, end_date=20250803T065141
[2025-08-03T06:51:41.099+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T06:51:41.314+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T06:51:41.316+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T06:53:11.668+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T06:53:11.696+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:53:11.702+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:53:11.702+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T06:53:11.716+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T06:53:11.727+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1057) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T06:53:11.728+0000] {standard_task_runner.py:63} INFO - Started process 1059 to run task
[2025-08-03T06:53:11.727+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmpfkqlf9ar']
[2025-08-03T06:53:11.729+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask transform_data_task
[2025-08-03T06:53:12.003+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 19828dfd2b76
[2025-08-03T06:53:12.075+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T06:53:12.077+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T06:53:12.093+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T06:53:12.093+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T06:53:12.094+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T06:53:12.104+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:53:12.108+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-03T06:53:12.149+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-03T06:53:12.149+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-03T06:53:12.151+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T06:53:12.151+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:53:12.167+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T06:53:12.168+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T06:53:12.187+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T065311, end_date=20250803T065312
[2025-08-03T06:53:12.263+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T06:53:12.469+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T06:53:12.474+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T06:56:15.148+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T06:56:15.200+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:56:15.213+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T06:56:15.213+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T06:56:15.224+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T06:56:15.232+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1360) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T06:56:15.233+0000] {standard_task_runner.py:63} INFO - Started process 1362 to run task
[2025-08-03T06:56:15.233+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmphu9rwvel']
[2025-08-03T06:56:15.234+0000] {standard_task_runner.py:91} INFO - Job 37: Subtask transform_data_task
[2025-08-03T06:56:15.438+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host 19828dfd2b76
[2025-08-03T06:56:15.527+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T06:56:15.528+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T06:56:15.544+0000] {__init__.py:92} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T06:56:15.544+0000] {__init__.py:34} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T06:56:15.544+0000] {__init__.py:50} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T06:56:15.556+0000] {__init__.py:52} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:56:15.561+0000] {__init__.py:115} INFO - 呼叫演算法 'aggregate_product_data' 來自模組 'processor.transform.algos_1'
[2025-08-03T06:56:15.593+0000] {algos_1.py:29} INFO - 資料處理完成
[2025-08-03T06:56:15.593+0000] {__init__.py:127} INFO - 資料是 pd.DataFrame
[2025-08-03T06:56:15.595+0000] {__init__.py:138} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T06:56:15.595+0000] {__init__.py:147} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T06:56:15.607+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T06:56:15.607+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T06:56:15.617+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T065615, end_date=20250803T065615
[2025-08-03T06:56:15.687+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T06:56:15.915+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T06:56:15.919+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-08-03T10:17:33.763+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-03T10:17:33.800+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T10:17:33.812+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [queued]>
[2025-08-03T10:17:33.812+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-03T10:17:33.824+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_data_task> on 2025-06-25 00:00:00+00:00
[2025-08-03T10:17:33.834+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=468) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-03T10:17:33.835+0000] {standard_task_runner.py:63} INFO - Started process 470 to run task
[2025-08-03T10:17:33.835+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_bbbbbbb', 'transform_data_task', 'scheduled__2025-06-25T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_generator.py', '--cfg-path', '/tmp/tmpqqf95oyb']
[2025-08-03T10:17:33.836+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask transform_data_task
[2025-08-03T10:17:34.085+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_bbbbbbb.transform_data_task scheduled__2025-06-25T00:00:00+00:00 [running]> on host e703672a2137
[2025-08-03T10:17:34.193+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_bbbbbbb' AIRFLOW_CTX_TASK_ID='transform_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-06-25T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-25T00:00:00+00:00'
[2025-08-03T10:17:34.195+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-03T10:17:34.210+0000] {__init__.py:118} INFO - 執行 transform_data (資料轉換層)
[2025-08-03T10:17:34.211+0000] {__init__.py:58} INFO - _get_upstream_output_path 上游任務: {'extract_data_task'}
[2025-08-03T10:17:34.211+0000] {__init__.py:74} INFO - 任務 'transform_data_task' 從單一上游 'extract_data_task' 拉取資料
[2025-08-03T10:17:34.220+0000] {__init__.py:76} INFO - 拉取到的 redis_key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T10:17:34.224+0000] {__init__.py:43} INFO - 使用資料夾結構方法: product_analysis.aggregation
[2025-08-03T10:17:34.224+0000] {__init__.py:142} INFO - 呼叫方法 'product_analysis.aggregation' 來自模組 'processor.transform'
[2025-08-03T10:17:34.257+0000] {aggregation.py:22} INFO - 產品聚合分析完成, 產品數量: 4
[2025-08-03T10:17:34.258+0000] {__init__.py:153} INFO - 資料是 pd.DataFrame
[2025-08-03T10:17:34.261+0000] {__init__.py:163} INFO - 轉換後資料已存入 Redis，key=***_data:dag_bbbbbbb.transform_data_task
[2025-08-03T10:17:34.262+0000] {__init__.py:172} INFO - 刪除上游 Redis key: ***_data:dag_bbbbbbb.extract_data_task
[2025-08-03T10:17:34.277+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-08-03T10:17:34.278+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-03T10:17:34.287+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_bbbbbbb, task_id=transform_data_task, run_id=scheduled__2025-06-25T00:00:00+00:00, execution_date=20250625T000000, start_date=20250803T101733, end_date=20250803T101734
[2025-08-03T10:17:34.329+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-08-03T10:17:34.549+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-08-03T10:17:34.555+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
